{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy1.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GAzhM913Swxg",
        "colab_type": "text"
      },
      "source": [
        "# mounting\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Olw0yrHP-B04",
        "colab_type": "text"
      },
      "source": [
        "## 7th layers saved weights1 model1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e4pQE7lFAQTy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "COLAB = False\n",
        "\n",
        "if COLAB:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    directry = '/content/drive/My Drive/IML/task4/task4_handout/'\n",
        "else:\n",
        "    directry = 'task4_handout/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vreJXg_KREo-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "import torch \n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as data\n",
        "from torchvision import models, transforms\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import time\n",
        "import copy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gQCpPwcdU-ho",
        "colab_type": "text"
      },
      "source": [
        "# Load Dataset and prepare it for training\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L5QQcTb97ovI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# DataFrames that have image file's names for training and validation\n",
        "df_train = pd.read_csv(directry+'train_triplets.txt', sep=' ', names=('anchor', 'positive', 'negative'))\n",
        "df_test = pd.read_csv(directry+'test_triplets.txt', sep=' ', names=('A', 'B', 'C')) \n",
        "\n",
        "# the number of output dimention in the dataset\n",
        "num_dim = 108\n",
        "\n",
        "# reshaped image size\n",
        "input_size = 299\n",
        "\n",
        "# batch size\n",
        "batch_size = 32\n",
        "\n",
        "# the number of epochs to train for\n",
        "num_epochs = 15\n",
        "\n",
        "# whther train all the layers(False) or only reshaped layers(True)\n",
        "feature_extract = True\n",
        "\n",
        "# .. 5 -> 6 -> AuxLogits -> 7 -> output\n",
        "mixed = 7"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oaqc-4jCqO-9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train, df_val = train_test_split(df_train, test_size=0.1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qWWoKVXBB91a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MyDataset(data.Dataset):\n",
        "    def __init__(self, dir_path, input_size, phase, df):\n",
        "        super().__init__()\n",
        "        self.dir_path = dir_path\n",
        "        self.input_size = input_size\n",
        "        self.anchor_image_paths = [p for p in map(lambda x: self.dir_path + str(x).zfill(5) + '.jpg', df['anchor'])]\n",
        "        self.positive_image_paths = [p for p in map(lambda x: self.dir_path + str(x).zfill(5) + '.jpg', df['positive'])]\n",
        "        self.negative_image_paths = [p for p in map(lambda x: self.dir_path + str(x).zfill(5) + '.jpg', df['negative'])]\n",
        "        self.len = len(self.anchor_image_paths) # the same as positive_image_paths and negative_image_paths\n",
        "\n",
        "        if phase == \"train\":\n",
        "            self.transformer = transforms.Compose([\n",
        "                transforms.RandomResizedCrop(input_size),\n",
        "                transforms.RandomHorizontalFlip(),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "            ])\n",
        "        elif phase == \"val\":\n",
        "            self.transformer = transforms.Compose([\n",
        "                transforms.Resize(input_size),\n",
        "                transforms.CenterCrop(input_size),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "            ])\n",
        "        \n",
        "    def __len__(self):\n",
        "        return self.len\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        anchor = self.anchor_image_paths[index]\n",
        "        positive = self.positive_image_paths[index]\n",
        "        negative = self.negative_image_paths[index]\n",
        "        \n",
        "        # 入力\n",
        "        anchor_image = Image.open(anchor)\n",
        "        anchor_image = self.transformer(anchor_image)\n",
        "        positive_image = Image.open(positive)\n",
        "        positive_image = self.transformer(positive_image)\n",
        "        negative_image = Image.open(negative)\n",
        "        negative_image = self.transformer(negative_image)\n",
        "\n",
        "            \n",
        "        return anchor_image, positive_image, negative_image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kxDkXbfoDYDk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataset = MyDataset(directry+'food/', (input_size, input_size), 'train', df_train)\n",
        "val_dataset = MyDataset(directry+'food/', (input_size, input_size), 'val', df_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IqUzd9V37Jeb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataloader_dict = {'train': data.DataLoader(\n",
        "    train_dataset, batch_size=batch_size, shuffle=True,\n",
        "    num_workers=2, drop_last=True\n",
        ")}\n",
        "\n",
        "val_dataloader_dict = {'val': data.DataLoader(\n",
        "    val_dataset, batch_size=batch_size, shuffle=False,\n",
        "    num_workers=2, drop_last=True\n",
        ")}\n",
        "\n",
        "dataloaders_dict = dict()\n",
        "dataloaders_dict.update(train_dataloader_dict)\n",
        "dataloaders_dict.update(val_dataloader_dict)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VIy9YIJ0UqpC",
        "colab_type": "text"
      },
      "source": [
        "# Load pretrained inception model\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-_jVJARx0Rh4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def set_parameter_requires_grad(model, feature_extracting, mixed):\n",
        "    \"\"\"\n",
        "    \"\"\"\n",
        "    if feature_extracting:\n",
        "        if mixed == 6:\n",
        "            for name, param in model.named_parameters():\n",
        "                if not(name.startswith('Mixed_6') or name.startswith('AuxLogits') or name.startswith('Mixed_7')):\n",
        "                    param.requires_grad = False\n",
        "        elif mixed == 7:\n",
        "            for name, param in model.named_parameters():\n",
        "                if not(name.startswith('Mixed_7')):\n",
        "                    param.requires_grad = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cf7vrpF6zEud",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def initialize_model(num_dim, feature_extract,  mixed, use_pretrained=True):\n",
        "    # Initialize these variables which will be set in this if statement. Each of these\n",
        "    #   variables is model specific.\n",
        "    \"\"\" Inception v3\n",
        "    Be careful, expects (299,299) sized images and has auxiliary output\n",
        "    \"\"\"\n",
        "    model = models.inception_v3(pretrained=use_pretrained)\n",
        "    set_parameter_requires_grad(model, feature_extract, mixed)\n",
        "    # Handle the auxilary net\n",
        "    num_ftrs = model.AuxLogits.fc.in_features\n",
        "    model.AuxLogits.fc = nn.Linear(in_features=num_ftrs, out_features=num_dim)\n",
        "    # Handle the primary net\n",
        "    num_ftrs = model.fc.in_features\n",
        "    model.fc = nn.Linear(in_features=num_ftrs, out_features=num_dim)\n",
        "\n",
        "    return model\n",
        "\n",
        "# Initialize the model for this run\n",
        "model = initialize_model(num_dim, feature_extract, mixed, use_pretrained=True)\n",
        "\n",
        "# Print the model we just instantiated\n",
        "#print(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iQpPO6WAhg0m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "PATH = directry+'initial_model1.pt'\n",
        "torch.save(model, PATH)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9okt6UxEhiwI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "PATH = directry+'initial_model1.pt'\n",
        "model = torch.load(PATH)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "36MOLIdGOUS3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def softmax(outputs):\n",
        "  outputs = F.softmax(outputs, dim=1)\n",
        "  return outputs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eo-OXOvLuGRI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "params_to_update = model.parameters()\n",
        "print(\"Params to learn:\")\n",
        "if feature_extract:\n",
        "    params_to_update = []\n",
        "    for name, param in model.named_parameters():\n",
        "        if param.requires_grad == True:\n",
        "            params_to_update.append(param)\n",
        "            print(\"\\t\",name)\n",
        "else:\n",
        "    for name, param in model.named_parameters():\n",
        "        if param.requires_grad == True:\n",
        "            print(\"\\t\",name)\n",
        "\n",
        "# Observe that all parameters are being optimized\n",
        "optimizer = optim.SGD(params_to_update, lr=0.008, momentum=0.9)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZJs44PVduhrm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TripletLoss(nn.Module):\n",
        "    \"\"\"\n",
        "    Triplet loss\n",
        "    Takes embeddings of an anchor sample, a positive sample and a negative sample\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, margin = 1.0):\n",
        "        super(TripletLoss, self).__init__()\n",
        "        self.margin = margin\n",
        "\n",
        "    def forward(self, anchor, positive, negative):\n",
        "        dist_positive = (anchor - positive).pow(2).sum(1)  \n",
        "        dist_negative = (anchor - negative).pow(2).sum(1)  \n",
        "        losses = F.relu(dist_positive - dist_negative + self.margin)\n",
        "\n",
        "        return losses.mean()\n",
        "\n",
        "criterion = TripletLoss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6fgn9OjIezCE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_model(model, dataloaders, criterion, optimizer, num_epochs, mixed, feature_extract=True):\n",
        "    since = time.time()\n",
        "    \n",
        "    val_acc_history = []\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'val']:\n",
        "            num_batch = 0\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            # Iterate over data.\n",
        "            for anchor, positive, negative in dataloaders[phase]:\n",
        "                num_batch+=1 \n",
        "                anchor = anchor.to(device)\n",
        "                positive = positive.to(device)\n",
        "                negative = negative.to(device)\n",
        "          \n",
        "\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward\n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    if phase == 'train':\n",
        "                        # From https://discuss.pytorch.org/t/how-to-optimize-inception-model-with-auxiliary-classifiers/7958\n",
        "                        anchor_outputs, anchor_aux_outputs = model(anchor)\n",
        "                        positive_outputs, positive_aux_outputs = model(positive)\n",
        "                        negative_outputs, negative_aux_outputs = model(negative)\n",
        "\n",
        "                        anchor_outputs = softmax(anchor_outputs)\n",
        "                        positive_outputs = softmax(positive_outputs)\n",
        "                        negative_outputs = softmax(negative_outputs)\n",
        "                        if mixed == 6:\n",
        "                            anchor_aux_outputs = softmax(anchor_aux_outputs)\n",
        "                            positive_aux_outputs = softmax(positive_aux_outputs)\n",
        "                            negative_aux_outputs = softmax(negative_aux_outputs)\n",
        "                      \n",
        "                            loss1 = criterion(anchor_outputs, positive_outputs, negative_outputs)\n",
        "                            loss2 = criterion(anchor_aux_outputs, positive_aux_outputs, negative_aux_outputs)\n",
        "\n",
        "                            loss = loss1 + 0.3 * loss2\n",
        "\n",
        "                        elif mixed == 7:\n",
        "                            loss = criterion(anchor_outputs, positive_outputs, negative_outputs)\n",
        "        \n",
        "                    else:\n",
        "                        anchor_outputs = model(anchor)\n",
        "                        positive_outputs = model(positive)\n",
        "                        negative_outputs = model(negative)\n",
        "\n",
        "                        anchor_outputs = softmax(anchor_outputs)\n",
        "                        positive_outputs = softmax(positive_outputs)\n",
        "                        negative_outputs = softmax(negative_outputs)\n",
        "                      \n",
        "                        loss = criterion(anchor_outputs, positive_outputs, negative_outputs)\n",
        "  \n",
        "                  \n",
        "                    dist_positive = (anchor_outputs - positive_outputs).pow(2).sum(1)   # should be smaller\n",
        "                    dist_negative = (anchor_outputs - negative_outputs).pow(2).sum(1) # should be larger\n",
        "                    diff = dist_negative - dist_positive \n",
        "                    preds = diff > 0\n",
        "                  \n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                # statistics\n",
        "                running_loss += loss.item() * anchor.size(0) # anchor.size(0) is the same as batch size\n",
        "                running_corrects += torch.sum(preds == True)\n",
        "                #print(f'running_loss: {running_loss / (num_batch*32)}, num_example: {num_batch*32}')\n",
        "                #print()\n",
        "\n",
        "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
        "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
        "\n",
        "\n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
        "\n",
        "            # deep copy the model\n",
        "            if phase == 'val' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "            if phase == 'val':\n",
        "                val_acc_history.append(epoch_acc)\n",
        "\n",
        "        print()\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best val Acc: {:4f}'.format(best_acc))\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model, val_acc_history\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r1xSDccQDb5B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "PATH = directry+'model3.pt'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ba45U8a9u_op",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_ft, hist = train_model(model, dataloaders_dict, criterion, optimizer, num_epochs, mixed)\n",
        "torch.save(model_ft, PATH)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "byWbjdIqC2rg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_ft = torch.load(PATH)\n",
        "model_ft.eval()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zsZbFj9Y_RaK",
        "colab_type": "text"
      },
      "source": [
        "# Make predictions\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qT95KAu51nuC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MyTestDataset(data.Dataset):\n",
        "    def __init__(self, dir_path, input_size, df):\n",
        "        super().__init__()\n",
        "        self.dir_path = dir_path\n",
        "        self.input_size = input_size\n",
        "        self.a_image_paths = [p for p in map(lambda x: self.dir_path + str(x).zfill(5) + '.jpg', df['A'])]\n",
        "        self.b_image_paths = [p for p in map(lambda x: self.dir_path + str(x).zfill(5) + '.jpg', df['B'])]\n",
        "        self.c_image_paths = [p for p in map(lambda x: self.dir_path + str(x).zfill(5) + '.jpg', df['C'])]\n",
        "        self.len = len(self.a_image_paths) # the same as positive_image_paths and negative_image_paths\n",
        "        self.transformer = transforms.Compose([\n",
        "            transforms.Resize(input_size),\n",
        "            transforms.CenterCrop(input_size),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "        ])\n",
        "        \n",
        "    def __len__(self):\n",
        "        return self.len\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        a = self.a_image_paths[index]\n",
        "        b = self.b_image_paths[index]\n",
        "        c = self.c_image_paths[index]\n",
        "        \n",
        "        # 入力\n",
        "        a_image = Image.open(a)\n",
        "        a_image = self.transformer(a_image)\n",
        "        b_image = Image.open(b)\n",
        "        b_image = self.transformer(b_image)\n",
        "        c_image = Image.open(c)\n",
        "        c_image = self.transformer(c_image)\n",
        "\n",
        "        return a_image, b_image, c_image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ftc7BgfV13CR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_dataset = MyTestDataset(directry+'food/', (input_size, input_size), df_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_MfArsDnB_HT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict_func(model, image1, image2, image3):\n",
        "    \"\"\"For one set of three images\n",
        "    \"\"\"\n",
        "    image1_outputs = model(image1) # (1, 108)\n",
        "    image2_outputs = model(image2)\n",
        "    image3_outputs = model(image3)\n",
        "    dist_12 = (image1_outputs - image2_outputs).pow(2).sum(1).cpu()\n",
        "    dist_23 = (image1_outputs - image3_outputs).pow(2).sum(1).cpu()\n",
        "\n",
        "\n",
        "    return np.where(dist_12 < dist_23, int(1),  int(0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "57ZdeCRmI7Z1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_dataloader = data.DataLoader(\n",
        "    test_dataset, batch_size=128, shuffle=False,\n",
        "    num_workers=2, drop_last=False\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Od6JydyDzuY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "results = []\n",
        "\n",
        "model_ft.eval()\n",
        "\n",
        "for image1, image2, image3 in test_dataloader:\n",
        "  image1 = image1.to(device)\n",
        "  image2 = image2.to(device)\n",
        "  image3 = image3.to(device)\n",
        "  result = predict_func(model_ft, image1, image2, image3)\n",
        "  results.append(result)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RjiofD4IHJve",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_predict = pd.DataFrame(results)\n",
        "df_predict.to_csv(directry+'prediction1.txt', index=False, header=None, sep='\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_fcbXLmSRdyE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(directry+ 'prediction1.txt')\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fklNZEdlzTSN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}